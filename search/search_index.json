{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Deepracer wiki","text":"<p>Welcome to the Deepracer wiki!</p> <p>Here you will find step by step how to import and work with the AWS Deepracer in Carla Simulator.</p>"},{"location":"#documentation-links","title":"\ud83d\udcc4 Documentation links:","text":"<p>Here are the links to the different steps.</p> <p>How to create the racetracks and import them:</p> <ul> <li>Racetrack Creation</li> </ul> <p></p> <ul> <li>Include Racetrack in a CARLA Map</li> </ul> <p></p> <p>How the Deepracer was modeled and how to import it:</p> <ul> <li>Create DeepRacer</li> </ul> <p></p> <ul> <li>Import Deepracer to Carla</li> </ul> <p>How to use the Carla client to connect to the server:</p> <ul> <li>Client Usage</li> </ul> <p>How to connect a remote to drive the Deepracer (for testing or dataset generation)</p> <ul> <li>Remote control Deepracer</li> </ul> <p>In case you need help with the Unreal Engine 4 interface, here is a quick introduction guide:</p>"},{"location":"#introduction-to-carla-unreal-engine-4-interface-espanol","title":"Introduction to Carla, Unreal Engine 4 Interface (Espa\u00f1ol)","text":""},{"location":"clientusage/","title":"Carla client","text":""},{"location":"clientusage/#index","title":"Index:","text":"<ul> <li>Connection with server</li> <li>Deepracer Camera settings</li> <li>Client time vs real time</li> <li>HSV Filter and mask segmentation</li> <li>Generate Dataset</li> </ul> <p>(Map modified as the ramp has been added)</p>"},{"location":"clientusage/#connection-with-server","title":"Connection with server","text":"<p>Once the package is compressed at the carla root folder:</p> <pre><code>make package\n</code></pre> <p>Execute </p> <pre><code>CarlaUE4.sh\n</code></pre> <p>located at :</p> <pre><code>/Dist/CARLA_Shipping_0.9.15.2-2-gb23c01ae4-dirty/LinuxNoEditor\n</code></pre> <p>Now the server will be available to be connected to. Note that it can be launched with the flag ---RenderOffscreen to make it handier to use later.</p> <p>Then for the client, you have to create a python file (.py). </p> <p>We are going to use manualcontrol.py as an example, that will allow us to control the deepracer in the world we have just spawned. We will be using the keys W A S D as input: -      w: Move forward -      A: Turn left -      S: Brake -      D: Turn right</p> <p>First, you must import the required modules:</p> <pre><code>import carla\nimport time\nimport pygame\nimport numpy as np\n</code></pre> <ul> <li> <p>carla: CARLA client API</p> </li> <li> <p>time: for sleep/wait operations</p> </li> <li> <p>pygame: for keyboard input and display</p> </li> <li> <p>numpy: to process camera image data</p> </li> </ul> <p>Configuration for the CARLA server and the vehicle blueprint.</p> <pre><code>HOST = '127.0.0.1'\nPORT = 2000\nVEHICLE_MODEL = 'vehicle.finaldeepracer.aws_deepracer'\n</code></pre> <p>Initialize Pygame for displaying the RGB camera feed.</p> <pre><code>pygame.init()\nWIDTH, HEIGHT = 800, 600\nscreen = pygame.display.set_mode((WIDTH, HEIGHT))\npygame.display.set_caption(\"DeepRacer\")\n\n</code></pre> <p>Connect to CARLA, set timeout, and load a specific map (Town01).</p> <pre><code>client = carla.Client(HOST, PORT)\nclient.set_timeout(5.0)\nworld = client.get_world()\nclient.load_world('Town01') \n\n</code></pre> <p>Set sunny weather with clouds but no rain or fog.</p> <pre><code>weather = carla.WeatherParameters(\n    cloudiness=80.0,\n    precipitation=0.0,\n    sun_altitude_angle=90.0,\n    fog_density=0.0,\n    wetness=0.0\n)\nworld.set_weather(weather)\n</code></pre> <p>Spawn the DeepRacer Vehicle. Get the blueprint for the AWS DeepRacer vehicle.</p> <pre><code>blueprint_library = world.get_blueprint_library()\nvehicle_bp = blueprint_library.find(VEHICLE_MODEL)\n</code></pre> <p>Set vehicle spawn location and attempt to spawn it. If it fails, the program exits.</p> <pre><code>spawn_point = carla.Transform(carla.Location(x=2.95, y=-3.7, z=0.6),\n                carla.Rotation(pitch=0, yaw=-90, roll=0))\nvehicle = world.try_spawn_actor(vehicle_bp, spawn_point)\n</code></pre> <p>Attach an RGB Camera to the Vehicle.Configure the RGB camera sensor with resolution and field of view.</p> <pre><code>camera_rgb_bp = blueprint_library.find('sensor.camera.rgb')\ncamera_rgb_bp.set_attribute('image_size_x', str(WIDTH))\ncamera_rgb_bp.set_attribute('image_size_y', str(HEIGHT))\ncamera_rgb_bp.set_attribute('fov', '90')\n</code></pre> <p>Place and attach the camera to the vehicle.</p> <pre><code>camera_rgb_transform = carla.Transform(carla.Location(x=-1, z=0.5))\ncamera_rgb = world.spawn_actor(camera_rgb_bp, camera_rgb_transform, attach_to=vehicle)\n</code></pre> <p>Process RGB Image from Camera. Convert raw image data into a Pygame surface for display.</p> <pre><code>def process_rgb(image):\n    global camera_image_rgb\n    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n    array = np.reshape(array, (image.height, image.width, 4))[:, :, :3]\n    array = array[:, :, ::-1]\n    camera_image_rgb = pygame.surfarray.make_surface(array.swapaxes(0, 1))\n</code></pre> <p>Start listening to camera stream and process frames in real time:</p> <pre><code>camera_rgb.listen(lambda image: process_rgb(image))\n\n</code></pre> <p>Start the control loop and poll the keyboard.</p> <pre><code>control = carla.VehicleControl()\nrunning = True\n\nwhile running:\n    keys = pygame.key.get_pressed()\n    if keys[pygame.K_w]: ...\n    if keys[pygame.K_a]: ...\n    if keys[pygame.K_d]: ...\n    if keys[pygame.K_s]: ...\n    control.hand_brake = keys[pygame.K_SPACE]\n</code></pre> <p>Apply control values to the vehicle.</p> <pre><code>vehicle.apply_control(control)\n</code></pre> <p>Event Handling and Display</p> <pre><code>for event in pygame.event.get():\n        if event.type == pygame.QUIT or (event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE):\n            running = False\n\n\n    if camera_image_rgb:\n        screen.blit(camera_image_rgb, (0, 0))\n\n    pygame.display.flip()\n</code></pre> <p>Here is the FULL CODE: </p> <pre><code>import carla\nimport time\nimport pygame\nimport numpy as np\n\nHOST = '127.0.0.1'\nPORT = 2000\nVEHICLE_MODEL = 'vehicle.finaldeepracer.aws_deepracer'\n\npygame.init()\nWIDTH, HEIGHT = 800, 600\nscreen = pygame.display.set_mode((WIDTH, HEIGHT))\npygame.display.set_caption(\"DeepRacer\")\n\n\nclient = carla.Client(HOST, PORT)\nclient.set_timeout(5.0)\nworld = client.get_world()\nclient.load_world('Town01') \n\n\nweather = carla.WeatherParameters(\n    cloudiness=80.0,\n    precipitation=0.0,\n    sun_altitude_angle=90.0,\n    fog_density=0.0,\n    wetness=0.0\n)\nworld.set_weather(weather)\n\nblueprint_library = world.get_blueprint_library()\nvehicle_bp = blueprint_library.find(VEHICLE_MODEL)\n\n\nspawn_point = carla.Transform(carla.Location(x=2.95, y=-3.7, z=0.6),\n                carla.Rotation(pitch=0, yaw=-90, roll=0))\n\nvehicle = world.try_spawn_actor(vehicle_bp, spawn_point)\nif not vehicle:\n    print(\"unable to spanw\")\n    exit()\nprint(f\"vehicle {VEHICLE_MODEL} spaned at {spawn_point.location}\")\n\ncamera_rgb_bp = blueprint_library.find('sensor.camera.rgb')\ncamera_rgb_bp.set_attribute('image_size_x', str(WIDTH))\ncamera_rgb_bp.set_attribute('image_size_y', str(HEIGHT))\ncamera_rgb_bp.set_attribute('fov', '90')\n\n\ncamera_rgb_transform = carla.Transform(carla.Location(x=-1, z=0.5))\ncamera_rgb = world.spawn_actor(camera_rgb_bp, camera_rgb_transform, attach_to=vehicle)\n\n\ncamera_image_rgb = None\n\n\ndef process_rgb(image):\n    global camera_image_rgb\n    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n    array = np.reshape(array, (image.height, image.width, 4))[:, :, :3]\n    array = array[:, :, ::-1]\n    camera_image_rgb = pygame.surfarray.make_surface(array.swapaxes(0, 1))\n\n\n\ncamera_rgb.listen(lambda image: process_rgb(image))\n\ncontrol = carla.VehicleControl()\nrunning = True\n\nwhile running:\n    keys = pygame.key.get_pressed()\n\n    if keys[pygame.K_w]:\n        control.throttle = min(control.throttle + 0.01, 0.8)\n\n    else:\n        control.throttle = 0.0\n\n\n    control.brake = min(control.brake + 0.1, 1.0) if keys[pygame.K_s] else 0.0\n\n    if keys[pygame.K_a]:\n        control.steer = max(control.steer - 0.05, -1.0)\n\n    elif keys[pygame.K_d]:\n        control.steer = min(control.steer + 0.05, 1.0)\n\n    else:\n        control.steer = 0.0\n\n    control.hand_brake = keys[pygame.K_SPACE]\n\n    vehicle.apply_control(control)\n\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT or (event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE):\n            running = False\n\n\n    if camera_image_rgb:\n        screen.blit(camera_image_rgb, (0, 0))\n\n    pygame.display.flip()\n\n\ncamera_rgb.destroy()\nvehicle.destroy()\npygame.quit()\n\n</code></pre> <p>Now execute the code:</p> <pre><code>python3 manualcontrol.py\n</code></pre>"},{"location":"clientusage/#deepracer-camera-settings","title":"Deepracer Camera Settings","text":"<p>To replicate the same camera settings as the actual Deepracer (using the front POV camera). We will need these settings. They represent the location of the camera and its pitch, as it is a bit tilted and facing down.</p> <pre><code>camera_rgb_bp = blueprint_library.find('sensor.camera.rgb')\ncamera_rgb_bp.set_attribute('image_size_x', str(WIDTH))\ncamera_rgb_bp.set_attribute('image_size_y', str(HEIGHT))\ncamera_rgb_bp.set_attribute('fov', '120')\n\n\ntransform_front = carla.Transform(carla.Location(x=0.13, z=0.13), carla.Rotation(pitch=-30))\ncamera_front = world.spawn_actor(camera_rgb_bp, transform_front, attach_to=vehicle)\n</code></pre>"},{"location":"clientusage/#client-time-vs-real-time","title":"Client time vs real time","text":"<p>When using synchronous mode in CARLA, it is essential to run the simulator with a fixed time-step. Otherwise, the physics engine will try to \"catch up\" for the time the client spent idle, leading to unrealistic or inconsistent physics.</p> <p>What is Fixed Time-Step?</p> <p>In fixed time-step mode, the simulation advances by the same time increment on every <code>world.tick()</code> call, regardless of how fast your computer is. To enable this, we must set:</p> <pre><code>settings.synchronous_mode = True\nsettings.fixed_delta_seconds = 1.0 / 20.0  # 20 FPS\nworld.apply_settings(settings)\n</code></pre> <p>We want to observe the difference between:</p> <p>The real time it takes for the computer to perform one simulation step (world.tick()), and</p> <p>The callback frequency of the camera sensor (e.g. every time it sends an image frame).</p> <p>We define a camera_callback() function that prints the frame number and timestamp:</p> <pre><code>def camera_callback(image):\n    print(f\"[Frame {image.frame}] timestamp: {image.timestamp:.5f}\")\n\n</code></pre> <p>Inside the main loop, we also measure and print the real time gap between ticks:</p> <pre><code>while running:\n    t1 = time.time()\n    world.tick()\n    t2 = time.time()\n    print(f\"real time gap: {t2 - t1}\")\n</code></pre> <p>We get this output:</p> <pre><code>real time gap: 0.0028502941131591797\nreal time gap: 0.0028717517852783203\n[Frame 11578] timestamp: 162.86267\nreal time gap: 0.002864837646484375\n[Frame 11579] timestamp: 162.91267\n[Frame 11580] timestamp: 162.96267\nreal time gap: 0.0028464794158935547\n[Frame 11581] timestamp: 163.01267\nreal time gap: 0.002921581268310547\nreal time gap: 0.0028870105743408203\n[Frame 11582] timestamp: 163.06267\n[Frame 11583] timestamp: 163.11267\nreal time gap: 0.0028617382049560547\n[Frame 11584] timestamp: 163.16267\nreal time gap: 0.0031239986419677734\nreal time gap: 0.0028901100158691406\n[Frame 11585] timestamp: 163.21267\n[Frame 11586] timestamp: 163.26267\nreal time gap: 0.0029799938201904297\n\n</code></pre> <p>Interpretation</p> <p>Real time gap: 0.0028 means that world.tick() is being executed quickly (~2.8 ms per step) (the computer is fast).</p> <p>The camera callback prints roughly every 0.05 seconds, confirming it operates at the expected 20 FPS (1 / 20 = 0.05s).</p> <p>This demonstrates that:</p> <p>The simulation time advances deterministically by 0.05s per tick.</p> <p>The real time your PC takes to simulate one frame can be much less than 0.05s.</p> <p>This difference is expected and is the advantage of running the simulator as fast as possible while maintaining consistent simulation timing.</p> <p>Here is the code to try this out: </p> <pre><code>import carla\nimport time\nimport pygame\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nHOST = '127.0.0.1'\nPORT = 2000\nVEHICLE_MODEL = 'vehicle.finaldeepracer.aws_deepracer'\n\n\npygame.init()\nWIDTH, HEIGHT = 800, 600\nscreen = pygame.display.set_mode((WIDTH, HEIGHT))\npygame.display.set_caption(\"DeepRacer - RGB y Segmentaci\u00f3n Sem\u00e1ntica\")\n\n\nclient = carla.Client(HOST, PORT)\nclient.set_timeout(5.0)\nworld = client.get_world()\n\n#FPS\nsettings = world.get_settings()\nsettings.synchronous_mode = True\nsettings.fixed_delta_seconds = 1.0 / 20.0\nworld.apply_settings(settings)\n\nweather = carla.WeatherParameters(\n    cloudiness=80.0,\n    precipitation=0.0,\n    sun_altitude_angle=90.0,\n    fog_density=0.0,\n    wetness=0.0\n)\nworld.set_weather(weather)\n\nblueprint_library = world.get_blueprint_library()\nvehicle_bp = blueprint_library.find(VEHICLE_MODEL)\n\n\nspawn_point = carla.Transform(\n    carla.Location(x=3, y=-1, z=0.5),\n    carla.Rotation(yaw=-90)\n)\nvehicle = world.try_spawn_actor(vehicle_bp, spawn_point)\nif not vehicle:\n    print(\"Error spawning\")\n    exit()\n\n\ncamera_rgb_bp = blueprint_library.find('sensor.camera.rgb')\ncamera_rgb_bp.set_attribute('image_size_x', str(WIDTH))\ncamera_rgb_bp.set_attribute('image_size_y', str(HEIGHT))\ncamera_rgb_bp.set_attribute('fov', '120')\n\n\ntransform_front = carla.Transform(carla.Location(x=0.13, z=0.13), carla.Rotation(pitch=-30))\ntransform_thirdpers = carla.Transform(carla.Location(x=-1, z=0.75))\ncamera_front = world.spawn_actor(camera_rgb_bp, transform_front, attach_to=vehicle)\n\n\ndef camera_callback(image):\n    print(f\"[Frame {image.frame}] timestamp: {image.timestamp:.5f}\")\n\n\n\ncamera_front.listen(camera_callback)\n\n\ncontrol = carla.VehicleControl()\nrunning = True\n\nwhile running:\n\n    # Move on to the next iteration with world.tick()\n    t1 = time.time()\n    world.tick()\n    t2 = time.time()\n    print(f\"real time gap: {t2-t1}\")\n\n\ncamera_rgb.destroy()\nvehicle.destroy()\npygame.quit()\n</code></pre>"},{"location":"clientusage/#hsv-filter-and-mask-segmentation","title":"HSV Filter and mask segmentation","text":"<p>This section explains how the script processes RGB images from the front camera of the Deepracer in CARLA to create semantic segmentation masks based on color, using the HSV color space. We want to: - Detect white and yellow lane markings on the road. - Classify each pixel into a semantic class:   - <code>0</code>: background (black)   - <code>1</code>: white   - <code>2</code>: yellow - Save a colorized mask and use it for training or control logic.</p> <pre><code>hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n</code></pre> <p>The image is converted from RGB to HSV. HSV is preferred for color segmentation because this makes it easier to separate colors like white and yellow.</p>"},{"location":"clientusage/#create-color-masks","title":"Create Color Masks:","text":"<p>Yellow Mask</p> <pre><code>lower_yellow = np.array([18, 50, 150])\nupper_yellow = np.array([40, 255, 255])\nmask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n</code></pre> <p>White Mask</p> <pre><code>lower_white = np.array([0, 0, 200])\nupper_white = np.array([180, 30, 255])\nmask_white = cv2.inRange(hsv, lower_white, upper_white)\n</code></pre> <p>Create Semantic Class Mask</p> <p>Initialize a blank mask.</p> <p>Pixels detected as white are labeled as 1.</p> <p>Pixels detected as yellow are labeled as 2.</p> <pre><code>mask_class = np.zeros_like(mask_white, dtype=np.uint8)\nmask_class[mask_white &gt; 0] = 1\nmask_class[mask_yellow &gt; 0] = 2\n</code></pre>"},{"location":"clientusage/#convert-class-mask-to-rgb-for-visualization","title":"Convert Class Mask to RGB for Visualization","text":"<pre><code>mask_rgb = np.zeros_like(rgb)\nmask_rgb[mask_class == 1] = [255, 255, 255]  # white\nmask_rgb[mask_class == 2] = [255, 255, 0]    # yellow\n\n</code></pre> <p>This gives a visually interpretable image where:</p> <p>White areas are actual white ([255,255,255])</p> <p>Yellow areas are yellow ([255,255,0])</p> <p>Background remains black ([0,0,0])</p> <p>This mask_rgb is used for display (cv2.imshow) and for dataset generation (cv2.imwrite).</p>"},{"location":"clientusage/#generate-dataset","title":"Generate Dataset","text":"<p>To do so, we launch a script that creates a unique dataset folder based on the current timestamp:</p> <pre><code>currtime = str(int(time.time() * 1000))\nDATASET_ID = \"Deepracer_BaseMap_\" + currtime\n</code></pre> <pre><code>dataset/\n\u2514\u2500\u2500 Deepracer_BaseMap_&lt;timestamp&gt;/\n    \u251c\u2500\u2500 rgb/        \u2190 RGB images from the camera\n    \u251c\u2500\u2500 masks/      \u2190 Mask images with segmented classes\n    \u2514\u2500\u2500 dataset.csv \u2190 Metadata log\n</code></pre> <p>Each frame is processed and saved using the keep_data() function. </p> <ul> <li> <p>rgb_img is saved as-is.</p> </li> <li> <p>mask_class_img is a colorized version of the class mask:</p> <ul> <li> <p>Pixels labeled 1 (white) become [255, 255, 255]</p> </li> <li> <p>Pixels labeled 2 (yellow) become [255, 255, 0]</p> </li> <li> <p>Background stays black</p> </li> </ul> </li> </ul> <pre><code>RGB_DIR = os.path.join(DATASET_ID, \"rgb\")\nMASK_DIR = os.path.join(DATASET_ID, \"masks\")\nCSV_PATH = os.path.join(DATASET_ID, f\"dataset.csv\")\n\ndef keep_data(timestamp, rgb_img, mask_class_img, accel, steer, brake, speed, heading):\n    ...\n    cv2.imwrite(os.path.join(RGB_DIR, rgb_name), rgb_img)\n    cv2.imwrite(os.path.join(MASK_DIR, mask_name), cv2.cvtColor(mask_class_img, cv2.COLOR_RGB2BGR))\n\n</code></pre> <p>Each image is associated with a row in the CSV file:</p> <pre><code>writer.writerow([rgb_path_rel, mask_path_rel, timestamp, accel, steer, brake, speed, heading])\n\n</code></pre> <ul> <li>rgb_path  Relative path to the RGB image</li> <li>mask_path Relative path to the mask image</li> <li>timestamp Capture time in ms</li> <li>throttle  Throttle value at capture</li> <li>steer Steer value at capture</li> <li>brake Brake value at capture</li> <li>speed Vehicle speed in m/s</li> <li>heading   Heading angle in degrees</li> </ul>"},{"location":"clientusage/#using-a-mutex-lock-for-safe-image-access","title":"Using a Mutex (Lock) for Safe Image Access","text":"<p>This script uses a Python mutex (<code>Lock</code>) to ensure safe access to the camera image data, especially in a multithreaded context involving sensor callbacks from CARLA.</p>"},{"location":"clientusage/#why-use-a-mutex","title":"Why Use a Mutex?","text":"<p>CARLA sensors (like the RGB camera) call a callback function in a separate thread every time a new image arrives. Meanwhile, the main loop (running in another thread) may try to access that image.</p> <p>Without protection, this leads to race conditions where: - Data may be read while it's being written - The program may crash or behave inconsistently - You may process outdated or corrupted frames</p>"},{"location":"clientusage/#lock-setup","title":"Lock Setup","text":"<pre><code>from threading import Lock\nfrom collections import deque\n\nimage_queue = deque(maxlen=1)\nqueue_lock = Lock()\n</code></pre> <ul> <li>image_queue: stores only the latest image</li> <li>queue_lock: a mutex to synchronize access to the queue</li> </ul> <p>Every time a new image is received, the mutex is acquired with with queue_lock The queue is cleared (to keep only the latest image) The new image is appended safely.</p> <pre><code>def camera_callback(image):\n    with queue_lock:\n        image_queue.clear()\n        image_queue.append((int(time.time() * 1000), image))\n</code></pre>"},{"location":"clientusage/#safe-access-in-the-main-loop","title":"Safe Access in the Main Loop","text":"<p>The main loop locks the queue before accessing it If the image is too old (over 150 ms), it is discarded This avoids race conditions with the callback</p> <pre><code>with queue_lock:\n    if image_queue:\n        img_timestamp, image = image_queue[0]\n        age = int(time.time() * 1000) - img_timestamp\n        if age &lt;= MAX_IMAGE_AGE_MS:\n            image = image_queue.popleft()[1]\n        else:\n            image = None  # Image too old, discard\n    else:\n        image = None\n\n</code></pre>"},{"location":"createdeepracerinblender/","title":"How to create DeepRacer 3D Model","text":"<p>This video summarizes this webpage (Spanish dub):</p> <p>Get the Deepracer stl files</p> <p>First of all you need to get the car files, which can be found in the git repository:</p> <p>   GitHub - aws-deepracer/aws-deepracer </p> <p>To make it easier, here is the .stl file of the Deepracer chassis:</p> <p>   Deepracer chassis </p> <p>And here is the wheel .stl file:</p> <p>   Deepracer wheel </p> <p>Download both of them.</p> <p>Install Blender add-on:</p> <p>Go to this webpage and download the add-on:</p> <p>   Blender add-on </p> <p>Now open Blender and go to Edit\u2192Preferences. </p> <p>Then open de Add-ons section and click the Install button.</p> <p>Search for the zip file you have just downloaded and click on Install Add-on from File.</p> <p>Check if it is installed correctly by pressing N or by clicking on the tiny arrow located at the top right.:</p> <p></p> <p>Then a new window will pop up, you will find an Unreal Engine 4 Vehicle label:</p> <p></p> <p>If so, then the add-on will have been installed correctly.</p> <p>Now import the chassis and wheels meshes. Just click on File\u2192Import and select the type of file your meshes are (.stl).</p> <p></p> <p>Now, we are going to adjust chassis and wheels size to the actual size of the real life ones and then build up the car:</p> <p></p> <p>To do so, make sure you are using object mode:</p> <p>(Top left of the screen).</p> <p></p> <p>If not, change it using tab key.</p> <p>Click on the imported wheel and copy it other 3 times.</p> <p>Now use the editor to transform, locate and rotate the wheels and chassis so that they are displayed together like in the above image. You can either use this editor to do so:</p> <p></p> <p>Or use the R key to rotate manually, the S key to scale it manually, or this icon on the left to move the object:</p> <p></p> <p>It is really important to face the X axis positively:</p> <p></p> <p>Once it is done, it is time to use the add-on we have just installed before.</p> <p>Display the UE4 Vehicle label as mentioned before :</p> <p></p> <p>You have to fill those 5 void labels with the corresponding chassis and 4 wheels. You can either click on the gray  icon located on the right of each label and then manually click on each mesh or just click inside and select the corresponding mesh:  </p> <p></p> <p>(Do not worry about the mesh names now, you will have to change them later).</p> <p>Now click on Set Unit Scale  at the bottom of the UE4 Vehicle display window:</p> <p></p> <p>Then click on Rig Vehicle:</p> <p></p> <p>You will see that bones have just appeared. Each one in a different mesh.</p> <p>You can resize them in the bone length label. However resizing them does not affect the functionality, it is just for clearer visualization:</p> <p></p> <p>You will find your files in your collection, distributed in a similar way to this one:</p> <p></p> <p>Now it is the time to change some names, the only important ones are the bone ones and de vehicle base, they have to be named exactly the same as the names on the picture from above. If not, Unreal Engine will not recognize them in some further steps. Although bone names and vehicle base are the only important ones, I recommend using the same names that I am using for the rest of the meshes. Just double left click on each object or bone to change its name.</p> <p>Once all of the above is done, this scenario must be exported into a .fbx file ( the kind of file Unreal Engine handles).</p> <p>To do so, click on File\u2192Export\u2192FBX</p> <p></p> <p>Now, few things have to be done in this new window. Make sure to uncheck or select as in here:</p> <p></p> <p></p> <p>So that only armature and mesh are exported, axes are correctly set, as so the geometry.</p> <p>A new fbx file will be created.</p> <p>This video explains the whole process (apart from other configurations that won\u2019t be needed now) much better:</p>"},{"location":"importdeepracercarla/","title":"How to Import the DeepRacer in CARLA","text":"<p>Youtube videos</p> <p>These videos summarize this webpage. Part 1 summarizes how to import the Deepracer to Carla. Part 2 explains few settings to complete the implementation.</p>"},{"location":"importdeepracercarla/#english","title":"English","text":"<p>Part 1:</p> <p>Part 2:</p>"},{"location":"importdeepracercarla/#espanol","title":"Espa\u00f1ol","text":"<p>Parte 1:</p> <p>Parte 2:</p>"},{"location":"importdeepracercarla/#_1","title":"\u4e2d\u6587","text":"<p>\u7b2c1\u90e8\u5206:</p> <p>\u7b2c2\u90e8\u5206:</p> <p>Importing into unreal engine</p> <p>First of all, find the deepracer.fbx file you just exported from blender or just take this model:</p> <p>   Fbx model link </p> <p>Now, run:</p> <pre><code>make launch\n</code></pre> <p>in the carla root directory.</p> <p>Once Unreal Engine is open, navigate to:</p> <p>Carla\u2192Static\u2192Vehicles(or Cars/4Wheeled)</p> <p>Crate a new directory and name it: Deepracer. Navigate to this new directory  and click on the the green add/import button on the left. Click on Import to /Game/Carla/static\u2026.  Then select the .fbx file of the Deepracer.</p> <p>We will be using default settings, so just click on import in the window that just appeared.</p>"},{"location":"importdeepracercarla/#setting-the-physics-asset","title":"Setting the physics asset","text":"<p>You will now have 3 files in your content browser directory, the  mesh, the skeleton and the physics asset. Double click on the physics  asset to open it.</p> <p>Click on options on the Skeleton tree window. Click on show all.</p> <p>First, select the Vehicle_Base. In the\u00a0<code>Details</code>\u00a0menu on the right, change the\u00a0<code>Linear Damping</code>\u00a0to 0.0 in the\u00a0<code>Physics</code>\u00a0section. Check\u00a0<code>Simulation Generates Hit Events</code>\u00a0in the\u00a0<code>Collision</code>\u00a0section and change the\u00a0<code>Primitive Type</code>\u00a0from\u00a0<code>Capsule</code>\u00a0to\u00a0<code>Box</code>\u00a0in the\u00a0<code>Body Creation</code>\u00a0section. Then press\u00a0<code>Regenerate bodies</code>. The capsule will now change to a rectangular box. </p> <p></p> <p>Then select all the wheels in the Skeleton Tree window(Options and select Show all bones) . Click each wheel bone while pressing  Ctrl key to select them all. Then change the Primitive type in the body creation window to sphere. Then generate bodies.</p> <p>Make sure that 4 spheres have been created, one for each wheel.</p> <p>For the wheels, change\u00a0<code>Linear Damping</code>\u00a0to 0.0, set\u00a0<code>Physics Type</code>\u00a0to\u00a0<code>Kinematic</code>, and set\u00a0<code>Collision Response</code>\u00a0to\u00a0<code>Disabled</code>. Press\u00a0<code>Re-generate Bodies</code>\u00a0once more.</p> <p></p> <p>Do not forget to save your changes: </p> <p></p>"},{"location":"importdeepracercarla/#creating-the-animation","title":"Creating the animation","text":"<p>In the content browser directory where you have your new vehicle assets, right click and choose\u00a0<code>Animation &gt; Animation Blueprint</code>. In the popup that opens, search for\u00a0<code>VehicleAnimInstance</code>\u00a0in the\u00a0<code>Parent Class</code>\u00a0section and for the\u00a0<code>Target Skeleton</code>\u00a0search  for the skeleton corresponding to the deepracer, you should be able  to see the name in your content browser. After selecting these two  things press OK. This will create a new animation blueprint for your  vehicle.</p> <p>Rename it as <code>AnimBP_Deepracer</code></p> <p>To simplify things, we can copy the animation from another vehicle rather than building each block by ourselves.</p> <p>In a second content browser(Window\u2192Content Browser\u2192Content Bowser 2), open\u00a0<code>Content &gt; Carla &gt; Static &gt; Vehicles(or Cars) &gt; 4Wheeled</code>\u00a0and choose any vehicle(For example the Audia A2). </p> <p>Open the animation blueprint of your chosen vehicle and then copy all nodes that are not the\u00a0<code>Output pose</code>\u00a0node from this blueprint,</p> <p>to the new animation blueprint you have just crated in the Deepracer directory.(Ctrl+V in the Deepracer Animation Blueprint)</p> <p>Connect the nodes by dragging a new connection between the final node and the output node. </p> <p>Press compile and the animation blueprint is now set. Do not forget to save it all.</p>"},{"location":"importdeepracercarla/#creating-the-car-blueprint","title":"Creating the car blueprint","text":"<p>This blueprint will be the file Carla will be using when loading the car in Unreal.</p> <p>Navigate with your content browser into\u00a0<code>Content &gt; Carla &gt; Blueprints &gt; Vehicles</code> and create a new directory, name it Deepracer.</p> <p>Navigate with your content browser into\u00a0<code>Content &gt; Carla &gt; Blueprints &gt; Vehicles &gt; AudiA2</code>\u00a0or  a similar vehicle. In here you will find a set of blueprints set up for  the 4 wheels. Copy these into the directory containing your own vehicle(<code>Content &gt; Carla &gt; Blueprints &gt; Vehicles &gt; Deepracer</code>)   and rename them to ensure you can distinguish them later. Do it this way for each wheel: </p> <p>from BP_Lincoln_FLW to BP_Deepracer_FLW</p> <p>from BP_Lincoln_FRW to BP_Deepracer_FRW</p> <p>from BP_Lincoln_RLW to BP_Deepracer_RLW</p> <p>from BP_Lincoln_RRW to BP_Deepracer_RRW</p> <p>Open and change these settings on each of those four Blueprints:</p> <ul> <li>Change the mesh in Collision mesh (in Shape) to <code>Wheel_Shape</code>.</li> <li>Set shape radius to 3.75 and shape width to 4.0 (make sure to measure it in Blender) .The Z offset should be 0. Mass is 0.04 kg</li> <li>In the <code>Tire Config</code> section of the blueprint, use the <code>CommonTireConfig</code>.</li> <li>Compile and save the blueprint.</li> <li><code>Affected by handbrake</code> should be checked for both rear wheels(in RLW and RRW Blueprints).<code>Steer angle</code> should be set to the maximum intended steer angle(30) for both front wheels and set to zero for both rear wheels.</li> <li> <p>It is REALLY IMPORTANT to make sure that CommonTireConfig tires  are used, before continuing to the next step, double check for each wheel blueprint that this tire is set. If not, and the tire is not defined, much later, Unreal will crash and shut down without an apparent reason. This is why!!!</p> </li> <li> <p>For the suspension values, both front wheels must have these settings: </p> </li> <li>Suspension force offset: 0.0</li> <li>Suspension max raise: 0.1</li> <li>Suspension max drop: 0.1</li> <li>Suspension natural frecuency: 25.0</li> <li>Suspension damping ratio: 1.0</li> <li>Both rear wheels must have these settings: </li> <li>Suspension force offset: 0.0</li> <li>Suspension max raise: 1.5</li> <li>Suspension max drop: 2.0</li> <li>Suspension natural frecuency: 25.0</li> <li>Suspension damping ratio: 1.0</li> </ul> <p>[OPTIONAL] To make the car even more realistic, change the brake torque and hand brake torque values on each wheel BP to these ones:  </p> <p></p> <p>Now right click in the content browser directory (where your deepracer wheels blueprints are) and chose\u00a0<code>Blueprint Class</code>. Search in the\u00a0<code>All Classes</code>\u00a0menu for\u00a0<code>BaseVehiclePawn</code>\u00a0and choose this class. Name the blueprint as \u201cBP_Deepracer\u201d and open it. </p> <p>Select\u00a0<code>Mesh</code>\u00a0in the\u00a0<code>Components</code>\u00a0tab on the left and then click on the vehicle mesh(search for the deepracer mesh) into the Mesh section on the right hand side.</p> <p>In\u00a0<code>Anim Class</code>\u00a0search for the animation corresponding to the deepracer that you set up in the previous step.</p> <p>This next step is REALLY IMPORTANT, as it is not explained in any website tutorial and it is fundamental.</p> <p>Type \u201ccenter\u201d in the Search Details browser and search for Center of Mass Offset. Change it to x=0.0, y=0.0 and z=-0.1, if not, the center mass will be below the ground and the car will be unable to move properly, as a massive \u201cForce\u201d will be pulling the Deepracer down. That z = -0.1 allows us to control the car much easier, as the center off mass is lowered a tiny bit and closer to the ground, the deepracer will be more stabilized. </p> <p>Next, select\u00a0<code>Vehicle Movement</code>\u00a0in the\u00a0<code>Components</code>\u00a0menu of the blueprint class and in the right\u00a0<code>Details</code>\u00a0menu navigate to the\u00a0<code>Vehicle Setup</code>\u00a0section. </p> <p>Change the vehicle mass to 1.23 kg.</p> <p>Now in Wheel Setups, for each wheel class, find the wheel blueprint that you previously copied and renamed for the\u00a0<code>Wheel Class</code>\u00a0attribute.Make sure that each wheel class name corresponds to the bone name. For example :</p> <p>In wheel setups, open 0, in Wheel Class, select BP_Deepracer_FLW as it corresponds to the bone named as Wheel_Front_Left.</p> <p>Do the same for each wheel (1, 2 and 3 in Wheel Setups). </p> <p></p> <p>Now search for Mechanical Setup-&gt;Transimssion Setup. Uncheck Automatic transmission, set gear switch time to 0.5, final ratio to 4.0.  In the Gear Setup settings, delete all gears except for one: Gear 1 and set that Gear1 Gear Ratio to 2.0 and the ReverseGearRatio to -4.0. Clutch strength has to be 10. Compile and save.</p> <p></p> <p>Last step is setting up the link to this blueprint. </p> <p>Now navigate to <code>Content &gt; Carla &gt; Blueprints &gt; Vehicles &gt; VehicleFactory</code> and double click this to open the Vehicle Factory.</p> <p>Select the <code>Vehicles</code> node and expand the <code>Vehicles</code> item in the <code>Default value</code> section on the right hand side.</p> <p></p> <p>Press the plus icon to add your new vehicle. Scroll down to the last entry and expand it, it should be empty. Name the make as  \u201cDeepracer\u201dand model as \u201cAWS_Deepracer\u201d .</p> <p>In the class section find your blueprint class that you created in the previous step(BP_Deepracer).</p> <p>Leave the number of wheels as 4 and put the generation as 0. Compile and save. </p> <p>Carla looks for this <code>VehicleFactory</code> file that has the \u201clinks\u201d to all car configurations. What we are doing in here is adding a way for Carla to \u201cknow\u201d that there is a vehicle called Deepracer and where its configurations are.</p> <p>Do a global save for safety and you are now ready to run your vehicle in a simulation. !!!</p> <p>Press play in the unreal toolbar to run the simulation:</p> <p></p> <p>Once it is running, to check if it worked. This script spawns the deepracer on x=0,y=0,z=0.5 ,lets you operate the vehicle using WASD keys:</p> <p>   Script Link </p> <pre><code>python3 manualcontrol.py\n</code></pre> <p>If anything went wrong, make sure that you followed every step correctly. </p> <p>If Unreal crashes, it means that there is something missing and Unreal cannot load something that does not even exist. Such as the tires configuration or wheel blueprints that are not correctly called from the car blueprint.</p> <p>These are all files needed for this process (no need to be all in the same place):</p> <p></p> <p>Here is a video of the Deepracer once all these steps have been done:</p>"},{"location":"includeracetrackcarla/","title":"How to manually include the Racetrack in any CARLA map","text":"<p>CARLA requires map geometry information in <code>.fbx</code> format and OpenDRIVE information in <code>.xodr</code> format.</p> <p>There are several ways to import your map into CARLA. However, we will not need to create the whole map from scratch. We will be using an already made map and just adding the track mesh on top of its surface.</p> <p>You will actually use an already created map with its own assets, objects and other configurations. And just add the meshes of the road we have just created. You can take this racetrack fbx:</p> <p>   Fbx link </p> <p>Open Carla:</p> <pre><code>cd carla\nmake launch\n</code></pre> <p>In the Content Browser of the editor, navigate to <code>Content/Carla/Maps/BaseMap</code> and duplicate the map by right clicking on it and duplicating it, the, rename it to (.e.g)  RaceTrack.</p> <p></p> <p>Create a new folder with the name of your map package in the <code>Content/Carla/Maps</code> directory and save the duplicated map there.(e.g /RaceTrack).</p> <p>In the Content Browser of the Unreal Engine editor, navigate to that folder you have just created. Right click in the grey area and select <code>Import to /Game/Carla/Maps...</code> under the heading Import Asset.</p> <p></p> <p>In the configuration window that pops up, make sure:</p> <p>These options are unchecked:</p> <ul> <li>Auto Generate Collision</li> <li>Combine Meshes</li> <li>Force Front xAxis</li> </ul> <p>In the following drop downs, the corresponding options are selected:</p> <ul> <li>Normal Import Method -Import Normals</li> <li>Material Import Method - Create New Materials</li> </ul> <p>These options are checked:</p> <ul> <li>Convert Scene Unit</li> <li>Import Textures</li> </ul> <p></p> <p>If the Import textures box cannot be checked,  just with \u201cCreate New Materials\u201d will be alright.</p> <p>Click <code>Import</code>.</p> <p>The racetrack meshes will appear in the Content Browser. Select the meshes and drag them into the scene. Before that, make sure you have an appropriate ground to display the racetrack on. You can drag into the scene any  static mesh that can work as a suitable ground.</p> <p>Now it will look like this:</p> <p></p> <p>Scale and resize the meshes wherever you want using the Transform menu on the right sidebar:</p> <p></p> <p>Make sure to move the whole racetrack 0.01 up in Z axis so that it becomes visible.</p> <p>Instead of BaseMap you can either choose other map and delete everything on it that is not really necessary such as trees, barriers, bushes, wires, signals\u2026 and then drag the racetrack inside</p> <p></p> <p>As the racetrack gray color can sometimes interfere if we would like to divide the image into masks and separate them into white and yellow. We can change the track material. </p> <p></p> <p>Click on each track part while pressing ctrl in either the visualizer or the World outliner at the top right. </p> <p>You will be able to change the colors in the Details panel on the right, there you can see the three ones we are using. Element 0 representing the gray track, Element 1 the white borders and Element 2 the yellow middle line. Simply click on either label layout to change the color. To make it look black I have used an already existing material which is road_asphalt, the gray one which is imported once the track was imported, but you can create a new one manually and then select it in that same label. To create a new one, right click on the content browser and click on material.</p> <p>To change the gray color in road_asphalt, double click on that material and then double click on the param square to select any color you like.</p> <p></p> <p></p> <p></p>"},{"location":"racetrackcreation/","title":"How to Create the Racetrack","text":"<p>You will need to have Blender installed in your device, I use the 4.3.2 version (we are on February 2025).</p> <p>blender.org</p> <p>Now follow the steps from this repository.</p> <p>(Notice there are both Windows and Linux implementations, only follow the Linux steps)</p> <p>   GitHub - johschmitz/blender-driving-scenario-creator </p> <p>To check if it is installed correctly and use this add-on in the correct way, just open Blender, press N or click the little left arrow next to the navigation gizmo(Top right) to toggle the sidebar. </p> <p></p> <p>Click View, set <code>Clip Start</code> to 1 m and <code>Clip End</code> to 10000 m to avoid some 3D viewport clipping issues since the Blender default setting is targeted more towards smaller models. </p> <p>Click the Shading dropdown button (the little down arrow in the top right corner of the 3D viewport)</p> <p></p> <p>And select <code>Texture</code> to be able to directly see the road sign textures.</p> <p></p> <p>Open the Driving Scenario Creator Sidebar:</p> <p></p> <p>Now it will be really easy to define the whole track, just click on whether you\u2019d prefer to include in the track, either a straight road track, arc or clothoid\u2026</p> <p>Click on each one to be able to adjust their parameters:</p> <p></p> <p>Whenever you are selecting anything, just click ESC to \u2018free your mouse\u2019 from that mode, and you will be able to select a different one.</p> <p>You will notice how all different road tracks align once you are displaying them and the mouse itself will be placed on the center of the next track piece.</p> <p>Once you have your whole track done, for example:</p> <p></p> <p>Just click on Export driving Scenario, below the whole sidebar:</p> <p></p> <p>Now select the .fbx extension and export it in any directory you want.</p> <p></p> <p>This will generate these folders:</p> <p></p> <p>Notice that for Carla you will need the .fbx and the .xodr file. The .fbx file is located in /models/static_scene</p> <p>And the .xodr file is in the /xodr folder</p> <p>You can even check the OPENDrive file online to ensure it was created successfully:</p> <p>Online OpenDRIVE Viewer</p>"},{"location":"remotecontrol/","title":"Remote Control Deepracer","text":"<p>This guide explains how to use a PS4 Controller (Dualshock) connected to your local laptop to remotely control a vehicle in CARLA simulator running on a remote server. The connection between the joystick and CARLA is made through SSH and socket communication.</p> <p></p> <p>It was made like this, so that we could use a much better PC and connect it through SSH to our laptop. However, it can be all done in the same PC at once by directly sending data to the Carla server.</p> <p>Besides, any controller can be used, as long as you are able to get its data. This implementation was also tested in an Xbox Controller and Nintendo Switch Pro Controller and it worked as well. (Notice how each device sends messages in different ways with different intervals).</p> <p>Make sure that you have installed evdev Python package:</p> <pre><code>pip install evdev\n</code></pre> <p>Make sure it works by typing:</p> <pre><code>sudo evtest\n</code></pre> <pre><code>No device specified, trying to scan all of /dev/input/event*\nAvailable devices:\n/dev/input/event0:  Lid Switch\n/dev/input/event1:  Sleep Button\n/dev/input/event2:  Power Button\n/dev/input/event3:  Power Button\n/dev/input/event4:  AT Translated Set 2 keyboard\n/dev/input/event5:  CUST0001:00 04F3:30AA Mouse\n/dev/input/event6:  CUST0001:00 04F3:30AA Touchpad\n/dev/input/event7:  ETPS/2 Elantech Touchpad\n/dev/input/event8:  Corsair CORSAIR HARPOON RGB PRO Gaming Mouse\n/dev/input/event9:  Corsair CORSAIR HARPOON RGB PRO Gaming Mouse\n/dev/input/event10: Corsair CORSAIR HARPOON RGB PRO Gaming Mouse\n/dev/input/event11: MSI WMI hotkeys\n/dev/input/event12: gpio-keys\n/dev/input/event13: Video Bus\n/dev/input/event14: Video Bus\n/dev/input/event15: HDA Intel PCH Mic\n/dev/input/event16: HDA Intel PCH Headphone\n/dev/input/event17: HDA Intel PCH HDMI/DP,pcm=3\n/dev/input/event18: HDA Intel PCH HDMI/DP,pcm=7\n/dev/input/event19: HDA Intel PCH HDMI/DP,pcm=8\n/dev/input/event20: Sony Interactive Entertainment Wireless Controller\n/dev/input/event21: Sony Interactive Entertainment Wireless Controller Motion Sensors\n/dev/input/event22: Sony Interactive Entertainment Wireless Controller Touchpad\nSelect the device event number [0-22]: \n</code></pre> <p>In my case, I'm currently using a PS4 controller, and I only want to use its buttons \u2014 not the touchpad or sensors. As so, I'll be typing 20 and be able to watch the values changing from ranges 0-255 while moving the joysticks:</p> <pre><code>Event: time 1754051218.570172, -------------- SYN_REPORT ------------\nEvent: time 1754051218.574173, type 3 (EV_ABS), code 0 (ABS_X), value 65\nEvent: time 1754051218.574173, type 3 (EV_ABS), code 1 (ABS_Y), value 221\nEvent: time 1754051218.574173, type 3 (EV_ABS), code 3 (ABS_RX), value 87\nEvent: time 1754051218.574173, type 3 (EV_ABS), code 4 (ABS_RY), value 254\nEvent: time 1754051218.574173, -------------- SYN_REPORT ------------\nEvent: time 1754051218.578170, type 3 (EV_ABS), code 0 (ABS_X), value 55\nEvent: time 1754051218.578170, type 3 (EV_ABS), code 1 (ABS_Y), value 228\nEvent: time 1754051218.578170, type 3 (EV_ABS), code 3 (ABS_RX), value 81\nEvent: time 1754051218.578170, type 3 (EV_ABS), code 4 (ABS_RY), value 252\nEvent: time 1754051218.578170, -------------- SYN_REPORT ------------\nEvent: time 1754051218.582177, type 3 (EV_ABS), code 0 (ABS_X), value 46\nEvent: time 1754051218.582177, type 3 (EV_ABS), code 1 (ABS_Y), value 234\nEvent: time 1754051218.582177, type 3 (EV_ABS), code 3 (ABS_RX), value 75\nEvent: time 1754051218.582177, type 3 (EV_ABS), code 4 (ABS_RY), value 249\nEvent: time 1754051218.582177, -------------- SYN_REPORT ------------\nEvent: time 1754051218.586179, type 3 (EV_ABS), code 0 (ABS_X), value 39\nEvent: time 1754051218.586179, type 3 (EV_ABS), code 1 (ABS_Y), value 240\nEvent: time 1754051218.586179, type 3 (EV_ABS), code 3 (ABS_RX), value 69\nEvent: time 1754051218.586179, type 3 (EV_ABS), code 4 (ABS_RY), value 246\nEvent: time 1754051218.586179, -------------- SYN_REPORT ------------\nEvent: time 1754051218.590181, type 3 (EV_ABS), code 0 (ABS_X), value 34\nEvent: time 1754051218.590181, type 3 (EV_ABS), code 1 (ABS_Y), value 239\nEvent: time 1754051218.590181, type 3 (EV_ABS), code 3 (ABS_RX), value 62\nEvent: time 1754051218.590181, type 3 (EV_ABS), code 4 (ABS_RY), value 245\nEvent: time 1754051218.590181, -------------- SYN_REPORT ------------\n</code></pre> <p>If this worked for you, your device is connected.</p> <p>To test its workability, as we are using sockets, we will have the joystick client code on our laptop and the carla receiver in the remote server.</p>"},{"location":"remotecontrol/#how-to-run-it","title":"How to run it??","text":"<p>Step 1: Run Receiver on Remote Server:</p> <pre><code>python3 receiver_car_control.py\n</code></pre> <p>Step 2: SSH Port Forwarding (on local laptop)</p> <p>Open one terminal and connect ssh to the remote server. Make sure that you are using an available port, avoid the commonly used ones. In my case I'll be using PORT 1977</p> <pre><code>ssh -p PORT user@host\n</code></pre> <p>If you are using an intermediate remote pc to reach the final destination:</p> <pre><code>ssh -J user@midhost user@finalhost -L PORT:localhost:PORT\n</code></pre> <p>Keep this terminal open.</p> <p>Step 3: Run Joystick Client on Local Laptop</p> <pre><code>python3 joystick_client.py\n</code></pre>"},{"location":"remotecontrol/#joystick-client","title":"Joystick client","text":"<pre><code>import socket\nfrom evdev import InputDevice, categorize, ecodes, list_devices\nimport select\n\nHOST = 'localhost'\nPORT = 1977\n\n# Search for device\ndevices = [InputDevice(path) for path in list_devices()]\njoystick = None\nfor device in devices:\n    if \"Sony\" in device.name or \"Wireless Controller\" in device.name or \"PS4\" in device.name:\n        joystick = device\n        break\n\nif not joystick:\n    print(\"No PS4 controller found\")\n    exit()\n\nprint(f\"? Using device: {joystick.path} - {joystick.name}\")\n\n# Connect\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.connect((HOST, PORT))\n    print(\"? Connected to receiver\")\n\n    abs_x = 0\n    abs_z = 0     # L2\n    abs_rz = 0    # R2\n\n    for event in joystick.read_loop():\n        if event.type == ecodes.EV_ABS:\n            if event.code == ecodes.ABS_X:      # Left joystick (steer)\n                abs_x = event.value\n            elif event.code == ecodes.ABS_Z:    # L2\n                abs_z = event.value\n            elif event.code == ecodes.ABS_RZ:   # R2\n                abs_rz = event.value\n\n            # Send values\n            msg = f\"[ABS_X] {abs_x}[R2] {abs_rz}[L2] {abs_z}\\n\"\n            s.sendall(msg.encode())\n</code></pre>"},{"location":"remotecontrol/#receiver","title":"Receiver","text":"<p>This code simply allows you to check whether messages have been received or not:</p> <pre><code>import socket\n\nHOST = 'localhost'\nPORT = 1977\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST, PORT))\n    s.listen()\n    print(f\"Waiting for connection on {HOST}:{PORT}...\")\n    conn, addr = s.accept()\n    with conn:\n        print(f\"Connected from {addr}\")\n        while True:\n            data = conn.recv(1024)\n            if not data:\n                break\n            msg = data.decode().strip()\n            print(f\"{msg}\")\n</code></pre>"},{"location":"remotecontrol/#what-events-does-the-joystick-send-when-you-move-it","title":"What events does the joystick send when you move it?","text":"<p>When you move a game controller joystick (e.g., Nintendo Switch Pro Controller or PS4 DualShock) on Linux, the system sends axis events via the input system (like /dev/input/eventXX). These are the main axis events you receive:</p> <p>ABS_X:    Left joystick \u2013 Left/Right  From 0 to 255</p> <p>R2:   Right Trigger \u2013 From From 0 to 255</p> <p>L2:   Left Trigger \u2013 From From 0 to 255</p> <p>These values change dynamically as you move the sticks.</p> <p>Example of raw messages from the joystick If you print the raw values as they come in, you may see:</p> <pre><code>[ABS_X] 140[R2] 97[L2] 21\n[ABS_X] 140[R2] 100[L2] 21\n[ABS_X] 146[R2] 100[L2] 21\n[ABS_X] 146[R2] 100[L2] 20\n[ABS_X] 146[R2] 101[L2] 20\n[ABS_X] 150[R2] 101[L2] 20\n[ABS_X] 150[R2] 102[L2] 20\n[ABS_X] 154[R2] 102[L2] 20\n</code></pre> <p>These messages show axis events where the numbers indicate how far and in what direction the joystick or thrigger has been moved.</p> <p>Now we will use a manual control code to test this in a Carla world.</p> <p>Execute the Unreal Engine package from the carla root folder:</p> <pre><code>CarlaUE4.sh\n</code></pre> <p>located at :</p> <pre><code>/Dist/CARLA_Shipping_0.9.15.2-2-gb23c01ae4-dirty/LinuxNoEditor\n</code></pre> <p>Now the server will be available to be connected to. Note that it can be launched with the flag ---RenderOffscreen to make it handier to use later.</p> <p>Then for the client, you can use the same client code as before. For the remote receiver, you have to create a python file (.py) so that the Deepracer behaves as the joystick is sending data.</p> <pre><code>import carla\nimport time\nimport pygame\nimport numpy as np\nimport socket\n\n# Socket config\nHOST = 'localhost'\nPORT = 1977\n\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ns.bind((HOST, PORT))\ns.listen(1)\nprint(f\"Waiting for connection {HOST}:{PORT}...\")\nconn, addr = s.accept()\nprint(f\"Connected from {addr}\")\n\n# Carla config\nWIDTH, HEIGHT = 800, 600\npygame.init()\nscreen = pygame.display.set_mode((WIDTH, HEIGHT))\npygame.display.set_caption(\"DeepRacer - Remote control\")\n\nclient = carla.Client('127.0.0.1', 2000)\nclient.set_timeout(5.0)\nworld = client.get_world()\n\nweather = carla.WeatherParameters(\n    cloudiness=80.0,\n    precipitation=0.0,\n    sun_altitude_angle=90.0,\n    fog_density=0.0,\n    wetness=0.0\n)\nworld.set_weather(weather)\n\nblueprint_library = world.get_blueprint_library()\nvehicle_bp = blueprint_library.find('vehicle.finaldeepracer.aws_deepracer')\n\nspawn_point = carla.Transform(\n    carla.Location(x=-7, y=-15, z=0.5),\n    carla.Rotation(yaw=-15)\n)\n\nvehicle = world.try_spawn_actor(vehicle_bp, spawn_point)\nif not vehicle:\n    print(\"Unable to spawn vehicle\")\n    exit()\nprint(\"Vehicle spawned correctly\")\n\ncamera_bp = blueprint_library.find('sensor.camera.rgb')\ncamera_bp.set_attribute('image_size_x', str(WIDTH))\ncamera_bp.set_attribute('image_size_y', str(HEIGHT))\ncamera_bp.set_attribute('fov', '90')\ncamera_transform = carla.Transform(carla.Location(x=-1, z=0.5))\ncamera = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)\n\ncamera_image = None\ndef process_image(image):\n    global camera_image\n    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n    array = np.reshape(array, (image.height, image.width, 4))[:, :, :3]\n    array = array[:, :, ::-1]\n    camera_image = pygame.surfarray.make_surface(array.swapaxes(0, 1))\ncamera.listen(process_image)\n\n# Control vars\ncontrol = carla.VehicleControl()\ncurrent_steer = 0.0\ncurrent_throttle = 0.0\ncurrent_brake = 0.0\n\nrunning = True\nwhile running:\n    try:\n        buffer = conn.recv(1024).decode(errors='ignore').strip()\n        if not buffer:\n            continue\n\n        lines = buffer.splitlines()\n        for line in lines:\n            if \"[ABS_X]\" in line and \"[R2]\" in line and \"[L2]\" in line:\n                try:\n                    parts = line.strip().split(\"[ABS_X]\")\n                    if len(parts) &gt; 1:\n                        vals = parts[1].split(\"[R2]\")\n                        if len(vals) == 2:\n                            steer_val = int(vals[0].strip())\n                            rest = vals[1].split(\"[L2]\")\n                            if len(rest) == 2:\n                                r2_val = int(rest[0].strip())\n                                l2_val = int(rest[1].strip())\n\n                                # Escalar steer de 0-255 a -1 a 1\n                                current_steer = (steer_val - 127) / 128.0\n                                current_steer = max(-1.0, min(1.0, current_steer))\n\n                                # Escalar R2 (aceleraci\u00f3n) de 0-255 a 0.0-1.0\n                                current_throttle = max(0.0, min(1, r2_val / 255.0))\n\n                                # Escalar L2 (freno) de 255-0 a 0.001-0.1\n                                brake_normalized = 1.0 - (l2_val / 255.0)\n                                current_brake =  max(0.0, min(1.0, l2_val / 255.0))\n                except Exception as e:\n                    print(\"\u26a0\ufe0f Error parsing line:\", e)\n                    continue\n\n        # Apply control\n        control.steer = current_steer\n        control.throttle = current_throttle\n        control.brake = current_brake\n        vehicle.apply_control(control)\n\n        # Show camera\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                running = False\n        if camera_image:\n            screen.blit(camera_image, (0, 0))\n        pygame.display.flip()\n\n        # Speed display\n        velocity = vehicle.get_velocity()\n        speed = (velocity.x**2 + velocity.y**2 + velocity.z**2)**0.5\n        print(f\"Speed: {speed:.2f} m/s | Steer: {control.steer:.2f} | Throttle: {control.throttle:.2f} | Brake: {control.brake:.3f}\")\n\n    except KeyboardInterrupt:\n        print(\"Interrupted\")\n        break\n\n# Cleanup\ncamera.destroy()\nvehicle.destroy()\npygame.quit()\nconn.close()\ns.close()\nprint(\"Session ended.\")\n\n</code></pre>"}]}